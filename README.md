# credit-risk-classification
Module 20 Challenge - UWA/edX Data Analytics Bootcamp

Github repository at: [https://github.com/alyssahondrade/credit-risk-classification.git](https://github.com/alyssahondrade/credit-risk-classification.git)


## Table of Contents
1. [Introduction]()
    1. [Goal]()
    2. [Repository Structure]()
    3. [Dataset]()
2. [Approach]()
3. [Analysis]()


## Introduction

### Goal
The purpose of this analysis is to create a machine learning model that will predict loan risk based on historical lending activity.

The historical data is sourced from a peer-to-peer lending services company. It is a labelled dataset with a loan status of "healthy" (`0`) or "high-risk" (`1`), this is the variable the model will predict.

Examples of the historical data, the features, includes the:
- Loan size
- Interest rate
- Borrower income
- Debt to income ratio
- Number of accounts
- Derogatory remarks
- Total debt


### Repository Structure
- The root directory contains the source code: `credit_risk_classification.ipynb`

- The `Images` directory contains screenshots of the confusion matrices and classification reports.

- The `Resources` directory contains the raw dataset used in the model.


### Dataset
The dataset used in this analysis was generated by **edX Boot Camps LLC**.


## Approach
1. Split the data into training and testing sets
    - Read the raw data into a Pandas DataFrame.
    - Separate the y-variable (labels) and X-variable (features).
    - Split the data using `train_test_split`
        - Assign a `random_state` of 1 to the function.
        - Use `stratify` to ensure each outcome is represented proportionally.

2. Create a Logistic Regression Model with the original data
    - Use `lbfgs` as the solver.
    - Assign a `random_state` of 1, as above.
    - __ML Model 1__: unscaled dataset
        - Fit the model using the training data: `X_train` and `y_train`.
        - Make a prediction using the testing data: `X_test`.
        - Evaluate the performance using a confusion matrix and classification report.
    - __ML Model 2__: scaled dataset
        - Use `StandardScaler` to scale the data.
        - Fit the model using the scaled training data: `X_train_scaled` and `y_train`.
        - Make a prediction using the scaled testing data: `X_test_scaled`.
        - Evaluate the performance as above.

The approach above outlines the models to be compared in the analysis section. The following decisions were made during the machine learning process:

1. There are `75036` "healthy" samples and `2,500` "high-risk" samples. Given this imbalance in loan status, `stratify` is used during `train_test_split` to ensure each outcome is represented proportionally. Although non-stratified models explored in the process yielded better recall, using this model would be inappropriate due to the imbalance.

2. Although scaling in a logistic regression is not a requirement. This was explored whether it would provide improved performance, as it was noted the scale differences between the different features.

## Analysis

__No Scaling__

|![confusion_matrix_not_scaled](https://github.com/alyssahondrade/credit-risk-classification/blob/main/Images/CM_not_scaled.png)|![classification_report_not_scaled](https://github.com/alyssahondrade/credit-risk-classification/blob/main/Images/CR_not_scaled.png)|
|:---:|:---:|

__Scaled__
|![confusion_matrix_scaled](https://github.com/alyssahondrade/credit-risk-classification/blob/main/Images/CM_scaled.png)|![classification_report_scaled](https://github.com/alyssahondrade/credit-risk-classification/blob/main/Images/CR_scaled.png)|
|:---:|:---:|


