# credit-risk-classification
Module 20 Challenge - UWA/edX Data Analytics Bootcamp

Github repository at: [https://github.com/alyssahondrade/credit-risk-classification.git](https://github.com/alyssahondrade/credit-risk-classification.git)


## Table of Contents
1. [Introduction](https://github.com/alyssahondrade/credit-risk-classification/tree/main#introduction)
    1. [Goal](https://github.com/alyssahondrade/credit-risk-classification/tree/main#goal)
    2. [Repository Structure](https://github.com/alyssahondrade/credit-risk-classification/tree/main#repository-structure)
    3. [Dataset](https://github.com/alyssahondrade/credit-risk-classification/tree/main#dataset)
2. [Approach](https://github.com/alyssahondrade/credit-risk-classification/tree/main#approach)
3. [Analysis](https://github.com/alyssahondrade/credit-risk-classification/tree/main#analysis)
    1. [Without Scaling](https://github.com/alyssahondrade/credit-risk-classification/tree/main#without-scaling)
    2. [With Scaling](https://github.com/alyssahondrade/credit-risk-classification/tree/main#with-scaling)
    3. [Conclusion](https://github.com/alyssahondrade/credit-risk-classification/tree/main#conclusion)
4. [References]()


## Introduction

### Goal
The purpose of this analysis is to create a machine learning model that will predict loan risk based on historical lending activity.

The historical data is sourced from a peer-to-peer lending services company. It is a labelled dataset with a loan status of "healthy" (`0`) or "high-risk" (`1`), this is the variable the model will predict.

Examples of the historical data, the features, includes the:
- Loan size
- Interest rate
- Borrower income
- Debt to income ratio
- Number of accounts
- Derogatory remarks
- Total debt

The goal is to __minimise the false negatives__, as the cost of missing an actual positive is very high, hence focus on __recall__. Secondary to this would be minimising false positives, as investigations conducted on suspected fraudulent loans would be an acceptable tradeoff.

### Repository Structure
- The root directory contains the source code: `credit_risk_classification.ipynb`

- The `Images` directory contains screenshots of the confusion matrices and classification reports.

- The `Resources` directory contains the raw dataset used in the model.


### Dataset
The dataset used in this analysis was generated by **edX Boot Camps LLC**.


## Approach
1. Split the data into training and testing sets
    - Read the raw data into a Pandas DataFrame.
    - Separate the y-variable (labels) and X-variable (features).
    - Split the data using `train_test_split`
        - Assign a `random_state` of 1 to the function.
        - Use `stratify` to ensure each outcome is represented proportionally.

2. Create a Logistic Regression Model with the original data
    - Use `lbfgs` as the solver.
    - Assign a `random_state` of 1, as above.
    - __Model 1__: unscaled dataset
        - Fit the model using the training data: `X_train` and `y_train`.
        - Make a prediction using the testing data: `X_test`.
        - Evaluate the performance using a confusion matrix and classification report.
    - __Model 2__: scaled dataset
        - Use `StandardScaler` to scale the data.
        - Fit the model using the scaled training data: `X_train_scaled` and `y_train`.
        - Make a prediction using the scaled testing data: `X_test_scaled`.
        - Evaluate the performance as above.

The approach above outlines the models to be compared in the analysis section. The following decisions were made during the machine learning process:

1. There are `75,036` "healthy" samples and `2,500` "high-risk" samples. Given this imbalance in loan status, `stratify` is used during `train_test_split` to ensure each outcome is represented proportionally. Although non-stratified models explored in the process yielded better recall, using this model is not suitable as the improved performance could be attributed to the larger sample size of the better performing "healthy" predictions (with `100%` for precision and recall).

2. Although scaling in a logistic regression is not a requirement. This was explored whether it would provide improved performance, as it was observed there were scale differences between the different features.

## Analysis

### Without Scaling
|![confusion_matrix_not_scaled](https://github.com/alyssahondrade/credit-risk-classification/blob/main/Images/CM_not_scaled.png)|![classification_report_not_scaled](https://github.com/alyssahondrade/credit-risk-classification/blob/main/Images/CR_not_scaled.png)|
|:---:|:---:|
|Confusion Matrix|Classification Report|

- The accuracy of the model is `99%`.
- For the `healthy` class, the precision and recall are both `100%`.
- For the `high-risk` class, the precision is `87%` while recall is `89%` - contributing to an F1-score of `88%`.
- There are `67` false negatives and `80` false positives.

### With Scaling
|![confusion_matrix_scaled](https://github.com/alyssahondrade/credit-risk-classification/blob/main/Images/CM_scaled.png)|![classification_report_scaled](https://github.com/alyssahondrade/credit-risk-classification/blob/main/Images/CR_scaled.png)|
|:---:|:---:|
|Confusion Matrix|Classification Report|

- The accuracy of the model is also `99%`.
- As without scaling, the precision and recall for the `healthy` class is `100%`.
- For the `high-risk` class:
    - The precision remained the same at `87%`.
    - The recall increased, from `89%` without scaling to `98%` with scaling.
    - The F1-score increased from `88%` without scaling to `92%` with scaling.
- The number of false negatives decreased by `82%`, from `67` to `12`. This means that only `12` fraudulent loans were missed.
- The number of false positives increased by `13%`, from `80` to `90`. This means an extra `10` healthy loans were suspected as high-risk and investigated.

| False Negatives | False Positives |
|:---:|:---:|
| $$\frac{100 * (12-67)}{67} = -82\\% $$ | $$\frac{100 * (90-80)}{80} = 13\\% $$ |

### Conclusion
It is recommended to use the __Model 2__, which uses scaling, as it retains the `99%` model accuracy whilst optimising recall.

This model minimises the false negatives, with a decrease of `82%` from __Model 1__, meaning only `12` fraudulent loans were missed compared to `67`. This is acceptable, despite the `13%` increase in false positives, meaning an extra `10` healthy loans were suspected as high-risk and investigated.

This model is recommended for its high accuracy and optimised tradeoff between identifying fraudulent loans (false negatives) and undertaking investigations on healthy loans (false positives).

## References
- [1] Imbalanced Data - [https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data](https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/imbalanced-data)
